{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"./Retinal Fundus Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'val']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_greyscale(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20077 images belonging to 11 classes.\n",
      "Found 433 images belonging to 11 classes.\n",
      "Found 1236 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "#since test-train-val directories are already created, going to create generators\n",
    "\n",
    "size = 500\n",
    "samples = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255.0,\n",
    "    preprocessing_function = rgb_to_greyscale\n",
    "    # rotation_range = 20,\n",
    "    # width_shift_range = 0.02,\n",
    "    # height_shift_range = 0.02,\n",
    "    # shear_range = 0.001,\n",
    "    # zoom_range = 0.02,\n",
    "    # horizontal_flip = True,\n",
    "    # vertical_flip = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = os.path.join(file_dir, 'train'),\n",
    "    batch_size = samples,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (size, size),\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.0, preprocessing_function = rgb_to_greyscale)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory = os.path.join(file_dir, 'val'),\n",
    "    batch_size = samples,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (size,size)\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.0, preprocessing_function = rgb_to_greyscale)\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    directory = os.path.join(file_dir, 'test'),\n",
    "    batch_size = samples,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (size,size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 500, 500, 32)      1568      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 125, 125, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 41, 41, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 41, 41, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 10816)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               2769152   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 11)                5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,963,371\n",
      "Trainable params: 2,963,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "2008/2008 [==============================] - 151s 75ms/step - loss: 1.0249 - accuracy: 0.5820 - val_loss: 1.0823 - val_accuracy: 0.5658\n",
      "Epoch 2/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.7337 - accuracy: 0.6778 - val_loss: 0.9389 - val_accuracy: 0.5566\n",
      "Epoch 3/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.6338 - accuracy: 0.7197 - val_loss: 0.8951 - val_accuracy: 0.6005\n",
      "Epoch 4/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.5630 - accuracy: 0.7485 - val_loss: 0.8369 - val_accuracy: 0.6074\n",
      "Epoch 5/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.5205 - accuracy: 0.7702 - val_loss: 0.9477 - val_accuracy: 0.6005\n",
      "Epoch 6/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.4571 - accuracy: 0.7938 - val_loss: 0.8702 - val_accuracy: 0.6443\n",
      "Epoch 7/25\n",
      "2008/2008 [==============================] - 148s 74ms/step - loss: 0.4237 - accuracy: 0.8098 - val_loss: 0.8940 - val_accuracy: 0.6582\n",
      "Epoch 8/25\n",
      "2008/2008 [==============================] - 149s 74ms/step - loss: 0.3807 - accuracy: 0.8302 - val_loss: 0.9195 - val_accuracy: 0.6605\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (4,4), activation = 'relu', padding = 'same', input_shape = (size, size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((4,4)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.MaxPooling2D((3,3)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.MaxPooling2D((3,3)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(11, activation = 'softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data =  validation_generator,\n",
    "        epochs = 25,\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 4)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(\"bad_model_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3f9b9e2c84dd319003698fc684ead22f769b71014b59713d46cc8251cf0f9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
